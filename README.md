# OTUS_HW_Logs  
Выполнила ДЗ по анализу логов веб-сервера.    
В файле log_analysis.py лежит скрипт, который предоставляет возможность анализа логов веб-сервера в формате текстовых файлов.  
Он извлекает и агрегирует информацию о запросах, включая общее количество выполненных запросов, количество запросов по HTTP-методам, топ 3 IP адресов, с которых было сделано наибольшее количество запросов, и топ 3 самых долгих запросов.  
Собранная статистика сохраняется в JSON файл, имя которого представляет собой имя файла лога с окончанием "_stats".  
Существует возможность при запуске скрипта указывать как директорию (тогда скрипт проанализирует все лог файлы этой директории), так и отдельные лог файлы.    

Описание работы скрипта:  
main():  
В функции main сначала запрашивается путь до директории или лог файла. Проверяется, что введенный путь существует.  
Затем проверяется, является ли путь файлом или директорией, и создает список log_files.  
Для каждого лог файла вызывается analyze_logs(), после чего результаты печатаются в терминале и сохраняются в JSON-файл с помощью вызова функции save_to_json.    
analyze_logs():  
Сначала определяем переменные requests, methods, ips, slow возвращаемыми значениями функции parse_log_file.  
Анализируем полученные значения, объединяем и возвращаем их в виде требуемого словаря.
Принцип получения словарей top_ips_dict и top_slow_requests:
1. Словарь top_ips_dict, содержащий топ 3 IP адреса, с которых было сделано наибольшее количество запросов. 
В функции sorted() первый параметр - это список кортежей из словаря ips, который мы хотим отсортировать.
Второй параметр определяет функцию, по которой происходит сортировка. Таким образом, мы сортируем пары ключ-значение (IP и число запросов) по количеству запросов.
Третий параметр reverse=True означает, что сортировка будет производиться в порядке убывания.
Срез [:3] используется для получения первых трех элементов из отсортированного списка.
2. Словарь top_slow_requests, содержащий топ 3 самых долгих запросов.  
Логика работы функции sorted() в данном случае аналогична пункту 1 выше, только сортируем по параметру длительности запроса.    
parse_log_file():  
Эта функция принимает лог файл и выполняет его парсинг.  
Инициализация переменных:  
total_requests: количество обработанных запросов (инициализируется нулем).  
method_counts: словарь для подсчета запросов по методам. Используется defaultdict(int), что позволяет автоматически инициализировать отсутствующие ключи значением по умолчанию (0).  
ip_counts: словарь для подсчета запросов от уникальных IP-адресов.  
slow_requests: список для хранения информации о медленных запросах.  
Каждая строка файла проверяется на соответствие шаблону log_pattern. Если строка совпадает, увеличивается счетчик total_requests, а также извлекаются необходимые данные с помощью метода group().  
Так же увеличивается счетчик для каждого метода (method_counts) и счетчик количества запросов от IP-адресов (ip_counts).  
И записывается информация о медленных запросах в список slow_requests.  
Возвращаем полученные данные total_requests, method_counts, ip_counts, slow_requests, которые затем используются в функции analyze_logs.  
